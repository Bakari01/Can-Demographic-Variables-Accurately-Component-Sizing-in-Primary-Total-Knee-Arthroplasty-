{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaching a regression problem with multiple targets (also known as multi-output regression) involves similar steps to a single-output regression, but there are some additional considerations. Here's a general approach:\n",
    "\n",
    "1. **Understand the problem and data**: Understand the problem domain, the meaning of each feature, and the relationship between the features and the targets. Perform exploratory data analysis to get insights into the data.\n",
    "\n",
    "2. **Preprocess the data**: Clean the data, handle missing values, outliers, and encode categorical variables. Normalize or standardize the data if necessary.\n",
    "\n",
    "3. **Feature selection/engineering**: Depending on the complexity of the dataset, you might need to perform feature selection or engineer new features that can help improve the model's performance.\n",
    "\n",
    "4. **Model selection**: Choose a suitable model. Some regression models like linear regression, decision trees, and neural networks can directly handle multiple targets. For models that don't support multi-output regression directly, you can use wrapper methods like `MultiOutputRegressor` in scikit-learn.\n",
    "\n",
    "5. **Train the model**: Split the data into a training set and a test set. Fit the model to the training data.\n",
    "\n",
    "6. **Evaluate the model**: Use appropriate metrics to evaluate the model's performance on the test set. For regression tasks, common metrics include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared.\n",
    "\n",
    "7. **Hyperparameter tuning**: Use methods like grid search or random search to find the optimal hyperparameters for your model.\n",
    "\n",
    "8. **Interpret the model**: Depending on the model used, interpret the results and understand the relationship between the features and the targets.\n",
    "\n",
    "9. **Iterate**: Based on the performance and interpretation of the model, you might need to go back to previous steps and make adjustments, such as collecting more data, engineering new features, or trying different models.\n",
    "\n",
    "Remember, the key to a successful machine learning project is iteration. It's unlikely that you'll get everything perfect on the first try, so be prepared to go through this process multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import mlflow\n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "import sklearn\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore all warning messages (for production use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "def load_data(train_file_path, test_file_path):\n",
    "    try:\n",
    "        train_tka = pd.read_csv(train_file_path)\n",
    "        test_tka = pd.read_csv(test_file_path)\n",
    "        return train_tka, test_tka\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please provide valid file paths.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while loading the data:\", str(e))\n",
    "        return None, None\n",
    "\n",
    "train_file_path = r'C:\\Users\\HP\\Desktop\\Predicting-Component-Sizing-in-Primary-Total-Knee-Arthroplasty-using-Demographic-Variables\\Data\\ForModeling\\tka_data.csv'\n",
    "test_file_path = r'C:\\Users\\HP\\Desktop\\Predicting-Component-Sizing-in-Primary-Total-Knee-Arthroplasty-using-Demographic-Variables\\Data\\ForModeling\\tka_data_test.csv'\n",
    "\n",
    "# Call the load_data function and capture the returned data in variables\n",
    "train_tka, test_tka = load_data(train_file_path, test_file_path)\n",
    "\n",
    "if train_tka is not None and test_tka is not None:\n",
    "    print('Data Loaded Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (3299, 3)\n",
      "Shape of targets: (3299, 2)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and targets\n",
    "features = train_tka[['gender', 'height_cm', 'weight_kg']]\n",
    "targets = train_tka[['femur_dim', 'tibia_dim']]\n",
    "\n",
    "# Print the shape of features and targets\n",
    "print(\"Shape of features:\", features.shape)\n",
    "print(\"Shape of targets:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2639\n",
      "Testing set size: 660\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=8888)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating LinearRegression...\n",
      "Training and evaluating Ridge...\n",
      "Training and evaluating Lasso...\n",
      "Training and evaluating MultiOutputRegressor...\n",
      "Training and evaluating MultiOutputRegressor...\n",
      "Training and evaluating MultiOutputRegressor...\n",
      "Training and evaluating MultiOutputRegressor...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>3.301016</td>\n",
       "      <td>0.547154</td>\n",
       "      <td>2.589017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>3.300926</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>2.588998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>3.380034</td>\n",
       "      <td>0.523367</td>\n",
       "      <td>2.726230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiOutputRegressor</th>\n",
       "      <td>4.319664</td>\n",
       "      <td>0.213891</td>\n",
       "      <td>3.185699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiOutputRegressor</th>\n",
       "      <td>3.668615</td>\n",
       "      <td>0.433396</td>\n",
       "      <td>2.802775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiOutputRegressor</th>\n",
       "      <td>3.306121</td>\n",
       "      <td>0.544705</td>\n",
       "      <td>2.552612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiOutputRegressor</th>\n",
       "      <td>3.524324</td>\n",
       "      <td>0.479954</td>\n",
       "      <td>2.713290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RMSE  R2 Score       MAE\n",
       "Model                                             \n",
       "LinearRegression      3.301016  0.547154  2.589017\n",
       "Ridge                 3.300926  0.547178  2.588998\n",
       "Lasso                 3.380034  0.523367  2.726230\n",
       "MultiOutputRegressor  4.319664  0.213891  3.185699\n",
       "MultiOutputRegressor  3.668615  0.433396  2.802775\n",
       "MultiOutputRegressor  3.306121  0.544705  2.552612\n",
       "MultiOutputRegressor  3.524324  0.479954  2.713290"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base estimators\n",
    "base_estimators = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    MultiOutputRegressor(DecisionTreeRegressor(random_state=42)),\n",
    "    MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    MultiOutputRegressor(GradientBoostingRegressor(random_state=42)),\n",
    "    MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Create a pipeline for each base estimator, fit it to the data, make predictions, and evaluate the model\n",
    "for base_estimator in base_estimators:\n",
    "    print(f\"Training and evaluating {base_estimator.__class__.__name__}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('regression', base_estimator)  # Regression step\n",
    "    ])\n",
    "    pipeline.fit(X_train_scaled, y_train)\n",
    "    y_pred = pipeline.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append([base_estimator.__class__.__name__, rmse, r2, mae])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'RMSE', 'R2 Score', 'MAE'])\n",
    "\n",
    "# Set 'Model' as the index\n",
    "results_df.set_index('Model', inplace=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model, as measured by Mean Absolute Error (MAE), is then tuned and used to make predictions on the test set. The predictions are evaluated using the same metric, and the final model is then used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for regression...\n",
      "Best parameters: {'regression__estimator__learning_rate': 0.1, 'regression__estimator__max_depth': 3, 'regression__estimator__min_samples_leaf': 2, 'regression__estimator__n_estimators': 50}\n",
      "Best score: 11.25777294526315\n"
     ]
    }
   ],
   "source": [
    "# Define the base estimator and its parameter grid\n",
    "estimator = Pipeline([\n",
    "    ('regression', MultiOutputRegressor(GradientBoostingRegressor(random_state=42)))  # Regression step\n",
    "])\n",
    "parameters = {\n",
    "    'regression__estimator__n_estimators': [50, 100, 200],\n",
    "    'regression__estimator__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'regression__estimator__max_depth': [3, 5, 7],\n",
    "    'regression__estimator__min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV, fit it to the data, and print the best parameters and score\n",
    "print(f\"Tuning hyperparameters for {estimator.steps[-1][0]}...\")\n",
    "grid_search = GridSearchCV(estimator, parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.293770451756413\n",
      "R2 Score: 0.5478755067797553\n",
      "MAE: 2.55470550911337\n"
     ]
    }
   ],
   "source": [
    "# Define the best model with the best hyperparameters\n",
    "model = MultiOutputRegressor(GradientBoostingRegressor(learning_rate=0.1, n_estimators=50, max_depth=3, min_samples_leaf=2, random_state=42))\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.5858965365009\n",
      "R2 Score: 0.5471605917828155\n",
      "MAE: 2.811895769274299\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the tka_test dataset\n",
    "X_test_new = test_tka[['gender', 'height_cm', 'weight_kg']]\n",
    "y_test_new= test_tka[['femur_dim', 'tibia_dim']]\n",
    "\n",
    "# Scale the features\n",
    "X_test_scaled_new = scaler.transform(X_test_new)\n",
    "\n",
    "# Make predictions using the best model\n",
    "y_pred_test = model.predict(X_test_scaled_new)\n",
    "\n",
    "# Calculate the metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test_new, y_pred_test))\n",
    "r2 = r2_score(y_test_new, y_pred_test)\n",
    "mae = mean_absolute_error(y_test_new, y_pred_test)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# Store the predictions in a variable\n",
    "test_tka['femur_dim_pred'], test_tka['tibia_dim_pred'] = y_pred_test[:, 0], y_pred_test[:, 1]\n",
    "\n",
    "# Optionally, save the predictions to a file\n",
    "predictions_file_path = r'C:\\Users\\HP\\Desktop\\Predicting-Component-Sizing-in-Primary-Total-Knee-Arthroplasty-using-Demographic-Variables\\Data\\Predictions\\Predictions.csv'\n",
    "test_tka.to_csv(predictions_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Traching using MLflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure MLflow to point to the Azure Machine Learning workspace, and set it to the workspace tracking URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Configure MLflow to log to an Azure ML Workspace\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MLflow experiment, which allows us to group runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1709351654064, experiment_id='c91c0b77-be46-4cdc-a53d-f90e6561d8dc', last_update_time=None, lifecycle_stage='active', name=('Predicting Component Sizing in Primary Total Knee Arthroplasty using '\n",
       " 'Demographic Variables'), tags={}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the MLflow experiment\n",
    "experiment_name = \"Predicting Component Sizing in Primary Total Knee Arthroplasty using Demographic Variables\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the model, the metrics, and the parameters of the best model to the MLflow experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a run\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Train the model for a number of epochs\n",
    "    for epoch in range(100):\n",
    "\n",
    "        # Train the model for one epoch and get the predictions\n",
    "        # This is just a placeholder; replace it with your actual training code\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # Calculate the metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Log the metrics to the MLflow experiment\n",
    "        mlflow.log_metric(\"RMSE\", rmse, step=epoch)\n",
    "        mlflow.log_metric(\"R2 Score\", r2, step=epoch)\n",
    "        mlflow.log_metric(\"MAE\", mae, step=epoch)\n",
    "\n",
    "    # Log the model to the MLflow experiment\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Log the parameters of the best model to the MLflow experiment\n",
    "    mlflow.log_params(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.tracking.MlflowClient()\n",
    "experiment = mlflow_client.get_experiment_by_name(experiment_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
